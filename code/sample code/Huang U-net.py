# -*- coding: utf-8 -*-
"""femoral_nerve_block_computer_vision.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rkGuUPwE1pC7evUMiq8WrgDY0sr13Nx6
"""

# 导入相关模块 Import modules
import os
import sys
import random
import warnings

sys.path.append('./')

import numpy as np
import pandas as pd

import matplotlib.pyplot as plt


import tensorflow as tf
from keras.backend.tensorflow_backend import set_session


from tqdm import tqdm
from itertools import chain
from skimage import color
from skimage.io import imread, imshow, imread_collection, concatenate_images, imsave
from skimage.transform import resize
from skimage.morphology import label

from keras.models import Model, load_model
from keras.layers import Input
from keras.layers.core import Lambda
from keras.layers.convolutional import Conv2D, Conv2DTranspose
from keras.layers.pooling import MaxPooling2D
from keras.layers.merge import concatenate
from keras.callbacks import EarlyStopping, ModelCheckpoint
from keras import backend as K

# It's my dataset on google drive. You can use google drive too, and the files that were to he saved would not be lost.
#from google.colab import drive
#drive.mount('/content/drive')
#os.listdir("/content/drive/My Drive/testset")

# Clone dataset under the current directory
!git clone https://github.com/gscfwid/femoral_nerve_block_computer_vision

# Set some parameters，e.g., image size, file directories
IMG_WIDTH = 256
IMG_HEIGHT = 256
RGB_CHANNELS = 3
GS_CHANNELS = 1
# TRAIN_PATH = '/content/drive/My Drive/trainset/images/'
# TEST_PATH = '/content/drive/My Drive/testset/images/'
# TRAINMS_PATH = '/content/drive/My Drive/trainset/masks/'
# TESTMS_PATH = '/content/drive/My Drive/testset/masks_real/'
TRAIN_PATH = 'femoral_nerve_block_computer_vision/trainset/images/'
TEST_PATH = 'femoral_nerve_block_computer_vision/testset/images/'
TRAINMS_PATH = 'femoral_nerve_block_computer_vision/trainset/masks/'
TESTMS_PATH = 'femoral_nerve_block_computer_vision/testset/masks_real/'

warnings.filterwarnings('ignore', category=UserWarning, module='skimage')
seed = 42
random.seed = seed
np.random.seed = seed

print(os.listdir(TRAIN_PATH))

# Get train and test IDs
train_ids = [i.split('.')[0] for i in next(os.walk(TRAIN_PATH))[2]]  # 670 
test_ids = [i.split('.')[0] for i in next(os.walk(TEST_PATH))[2]]   # 65

#准备数据集 Prepare the dataset

def data_generator(train_ids,test_ids):
    #获取并resize训练集的图像和遮罩 get the training images and masks and resize them
    X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, GS_CHANNELS), dtype=np.uint8)
    Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)
    
    print('Getting and resizing train images and masks ...')
    sys.stdout.flush()
    for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):
        img = imread(TRAIN_PATH+id_+'.jpg')[:,:,:RGB_CHANNELS]
        img = resize(img,(IMG_HEIGHT,IMG_WIDTH),mode='constant',preserve_range=True)
        img = color.rgb2gray(img)
        img = np.expand_dims(img, 3)
        X_train[n] = img
#         mask = np.zeros((IMG_HEIGHT,IMG_WIDTH,1),dtype=np.bool)
        mask = imread(TRAINMS_PATH+id_+'.png')
        mask = color.rgb2gray(mask)
        mask = np.expand_dims(resize(mask, (IMG_HEIGHT, IMG_WIDTH), mode='constant',preserve_range=True), axis=-1)
#         mask = np.maximum(mask,mask_)
        Y_train[n] = mask
    
    #获取并resize测试集 get the test images and resize them
    X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, GS_CHANNELS), dtype=np.uint8)
    Y_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)
    sizes_test = []
    print('Getting and resizing test images ... ')
    sys.stdout.flush()
    for n, id_ in tqdm(enumerate(test_ids),total=len(test_ids)):
        img = imread(TEST_PATH + id_ + '.jpg')[:,:,:RGB_CHANNELS]
        sizes_test.append([img.shape[0], img.shape[1]])
        img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)
        img = color.rgb2gray(img)
        img = np.expand_dims(img, 3)
        X_test[n] = img
        
        mask = imread(TESTMS_PATH+id_+'.png')
        mask = color.rgb2gray(mask)
        mask = np.expand_dims(resize(mask, (IMG_HEIGHT, IMG_WIDTH), mode='constant',preserve_range=True), axis=-1)
#         mask = np.maximum(mask,mask_)
        Y_test[n] = mask
  
    print('Data Generate Done!')
    return X_train, Y_train, X_test, Y_test, sizes_test

X_train, Y_train, X_test, Y_test, sizes_test = data_generator(train_ids,test_ids)
print("Shape of X_train: " + str(X_train.shape))
print("Shape of X_test: " + str(X_test.shape))
print("Shape of Y_train: " + str(Y_train.shape))
print(sizes_test)

#检查数据是否正确 Chek the data

ix = random.randint(0, len(train_ids))
imshow(np.squeeze(X_train[ix]))
plt.show()
imshow(np.squeeze(Y_train[ix]))
plt.show()

# 定义metrics Definiation of metrics

# def mean_iou(y_true, y_pred):
#     prec = []
#     for t in np.arange(0.5, 1.0, 0.05):
#         y_pred_ = tf.to_int32(y_pred > t)
#         score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)
#         K.get_session().run(tf.local_variables_initializer())#这条代码应该是关键
#         with tf.control_dependencies([up_opt]):
#             score = tf.identity(score)
#         prec.append(score)
#     return K.mean(K.stack(prec), axis=0)
# def iou_loss_core(y_true, y_pred, smooth=1):
# #     ious = [] 
# #     for i_ in range(K.int_shape(y_true)[0]):
#     i = K.flatten(y_true)
#     j = K.flatten(y_pred)
#     intersection = K.sum(K.abs(i * j), axis=-1)
#     union = K.sum(i,-1) + K.sum(j,-1) - intersection
#     iou = (intersection + smooth) / ( union + smooth)
# #     ious.append(iou)
#     return iou
def dice_coef(y_true, y_pred,smooth=1):
    y_true_f = y_true
    y_pred_f = y_pred
    intersection = K.sum(y_true_f * y_pred_f)
    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)

def iou_coef(y_true, y_pred, smooth=1):
    y_true_f = K.flatten(y_true)
    y_pred_f = K.flatten(y_pred)
    intersection = K.sum(K.abs(y_true_f * y_pred_f), axis=-1)
    union = K.sum(y_true_f,-1) + K.sum(y_pred_f,-1) - intersection
    return (intersection + smooth) / ( union + smooth)

#搭建模型 Building the model
def UNetModel(IMG_HEIGHT,IMG_WIDTH,IMG_CHANNELS):#注意model的传入参数
    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))
    s = Lambda(lambda x: x / 255) (inputs)

    c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (s)
    c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (c1)
    p1 = MaxPooling2D((2, 2)) (c1)

    c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (p1)
    c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (c2)
    p2 = MaxPooling2D((2, 2)) (c2)

    c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (p2)
    c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (c3)
    p3 = MaxPooling2D((2, 2)) (c3)

    c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (p3)
    c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (c4)
    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)

    c5 = Conv2D(128, (3, 3), activation='relu', padding='same') (p4)
    c5 = Conv2D(128, (3, 3), activation='relu', padding='same') (c5)

    u6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c5)
    u6 = concatenate([u6, c4])
    c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (u6)
    c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (c6)

    u7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)
    u7 = concatenate([u7, c3])
    c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (u7)
    c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (c7)

    u8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)
    u8 = concatenate([u8, c2])
    c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (u8)
    c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (c8)

    u9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)
    u9 = concatenate([u9, c1], axis=3)
    c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (u9)
    c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (c9)

    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)

    model = Model(inputs=[inputs], outputs=[outputs])
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[iou_coef])
    return model

model = UNetModel(IMG_HEIGHT,IMG_WIDTH,GS_CHANNELS)

# fit the model
def model_fit(X_train,Y_train,model_name,epochs,batch_size,validation_split):
#     earlystopper = EarlyStopping(patience=5, verbose=1)
    checkpointer = ModelCheckpoint(model_name, verbose=1, save_best_only=True)
    results = model.fit(X_train,Y_train,validation_split=validation_split,
                       batch_size=batch_size,epochs=epochs,
                       callbacks=[checkpointer])
model_name = 'femoral_n_gs'
epochs = 75
batch_size = 32
validation_split = 0.1
model_fit(X_train,Y_train,model_name,epochs,batch_size,validation_split)

#预测模型 Prediction

model = load_model('femoral_n_gs', custom_objects={'iou_coef': iou_coef})
preds_train = model.predict(X_train[:int(X_train.shape[0]*0.9)], verbose=1)
preds_val = model.predict(X_train[int(X_train.shape[0]*0.9):], verbose=1)
preds_test = model.predict(X_test, verbose=1)

#二值化 binomial
preds_train_t = (preds_train > 0.5).astype(np.uint8)
preds_val_t = (preds_val > 0.5).astype(np.uint8)
preds_test_t = (preds_test > 0.5).astype(np.uint8)

# 上采样，回到原来的尺寸 upsampling to revert to original size
preds_test_upsampled = []
for i in range(len(preds_test)):
    preds_test_upsampled.append(resize(np.squeeze(preds_test_t[i]),
                                      (sizes_test[i][0], sizes_test[i][1]),
                                      mode='constant', preserve_range=True))
# for i in range(len(preds_val)):
#     preds_val_upsampled.append(resize(np.squeeze(preds_val_t[i]),
#                                       (sizes_test[i][0], sizes_test[i][1]),
#                                       mode='constant', preserve_range=True))

#模型评估 Evaluation
#获取trainset的IOU Get trainset IOUs

train_ious = []
for i in range(preds_train_t.shape[0]):
    intersection = np.sum(Y_train[i].astype(np.uint8) * preds_train_t[i])
    union = np.sum(Y_train[i].astype(np.uint8)) + np.sum(preds_train_t[i]) - intersection
    train_ious.append(intersection / union)
print(len(train_ious))
np_train = np.array(train_ious)
right_trainsum = np.sum((np_train>0.5).astype(np.uint8))
print(right_trainsum/len(train_ious))
print(np.median(np.array(train_ious)))
print(np.percentile(np.array(train_ious),75))
print(np.percentile(np.array(train_ious),25))

#total IOU for train set

intersection = np.sum(Y_train.astype(np.uint8)[:450]*preds_train_t)
union = np.sum(Y_train.astype(np.uint8)[:450])+np.sum(preds_train_t)-intersection
print(intersection/union)

#获取dev set的IOU Get dev set IOU

val_ious = []
for i in range(preds_val_t.shape[0]):
    intersection = np.sum(Y_train[i+int(Y_train.shape[0]*0.9)].astype(np.uint8) * preds_val_t[i])
    union = np.sum(Y_train[i+int(Y_train.shape[0]*0.9)].astype(np.uint8)) + np.sum(preds_val_t[i]) - intersection
    val_ious.append(intersection / union)
print(len(val_ious))
np_val = np.array(val_ious)
right_valsum = np.sum((np_val>0.5).astype(np.uint8))
print(right_valsum/len(val_ious))
print(np.median(np.array(val_ious)))
print(np.percentile(np.array(val_ious),75))
print(np.percentile(np.array(val_ious),25))

# Total IOU for dev set

intersection = np.sum(Y_train.astype(np.uint8)[450:]*preds_val_t)
union = np.sum(Y_train.astype(np.uint8)[450:])+np.sum(preds_val_t)-intersection
print(intersection/union)

# Check the 
ix = random.randint(0, len(preds_train_t))
imshow(np.squeeze(X_train[ix]))
plt.show()
imshow(np.squeeze(Y_train[ix]))# 128*128*1
plt.show()
imshow(np.squeeze(preds_train_t[ix])) # 128*128*1
plt.show()
intersection = np.sum(Y_train[ix].astype(np.uint8) * preds_train_t[ix])
union = np.sum(Y_train[ix].astype(np.uint8)) + np.sum(preds_train_t[ix]) - intersection
print(intersection/union)

# Perform a sanity check on some random validation samples
ix = random.randint(0, len(preds_val_t))
imshow(np.squeeze(X_train[int(X_train.shape[0]*0.9):][ix]))
plt.show()
imshow(np.squeeze(Y_train[int(Y_train.shape[0]*0.9):][ix]))
plt.show()
imshow(np.squeeze(preds_val_t[ix]))
plt.show()
intersection = np.sum(Y_train[ix+int(Y_train.shape[0]*0.9)].astype(np.uint8) * preds_val_t[ix])
union = np.sum(Y_train[ix+int(Y_train.shape[0]*0.9)].astype(np.uint8)) + np.sum(preds_val_t[ix]) - intersection
print(intersection/union)

#读取test数据 Load testset images
X_test_unsampled = []
for n, id_ in tqdm(enumerate(test_ids),total=len(test_ids)):
    img = imread(TEST_PATH + id_ + '.jpg')[:,:,:RGB_CHANNELS]
        
    X_test_unsampled.append(img)

# for i in range(len(preds_test)):
#     preds_test_upsampled.append(resize(np.squeeze(preds_test[i]),
#                                       (sizes_test[i][0], sizes_test[i][1]),
#                                       mode='constant', preserve_range=True))

# Check the test set
ix = random.randint(0, len(preds_test_upsampled))
imshow(np.squeeze(X_test_unsampled[ix]))
print(test_ids[ix])
plt.show()
imshow(preds_test_upsampled[ix])
plt.show()

# 保存masks_pred Save the predictive masks
for n,id_ in tqdm(enumerate(test_ids),total=len(test_ids)):
#     imsave('/content/drive/My Drive/testset/mask_pred_256gs/'+id_+'.png',preds_test_upsampled[n])
    imsave('femoral_nerve_block_computer_vision/testset/mask_pred_256gs/'+id_+'.png',preds_test_upsampled[n])

from skimage.io import imread, imshow, imread_collection, concatenate_images, imsave
import numpy as np
import matplotlib.pyplot as plt
from skimage import img_as_ubyte
import cv2

# 计算testset的IOU Calculate the test set IOUs

# test_img = next(os.walk('/content/drive/My Drive/testset/images/'))[2]
test_img = next(os.walk('/femoral_nerve_block_computer_vision/drive/My Drive/testset/images/'))[2]
# ix = random.randint(0, len(test_img))
plt.subplots_adjust(top=1,bottom=0,left=0,right=1,hspace=0,wspace=0)
plt.axis('off')
test_iou = []
intersection_t = 0
union_t = 0
for i in range(len(test_img)):
#     img1 = imread('/content/drive/My Drive/testset/images/'+test_img[i])
#     img2 = imread('/content/drive/My Drive/testset/masks_real/'+test_img[i][0:-4]+'.png')
#     img2 = color.rgb2gray(img2)
#     img3 = imread('/content/drive/My Drive/testset/mask_pred_256gs/'+test_img[i][0:-4]+'.png')
#     img3 = color.rgb2gray(img3)
    
    img1 = imread('/femoral_nerve_block_computer_vision/testset/images/'+test_img[i])
    img2 = imread('/femoral_nerve_block_computer_vision/testset/masks_real/'+test_img[i][0:-4]+'.png')
    img2 = color.rgb2gray(img2)
    img3 = imread('/femoral_nerve_block_computer_vision/testset/mask_pred_256gs/'+test_img[i][0:-4]+'.png')
    img3 = color.rgb2gray(img3)
    
    img2_idx_modified = img2[:,:] > 0
    img2[img2_idx_modified] = 1

    img3_idx_modified = img3[:,:] > 0
    img3[img3_idx_modified] = 1
    
    intersection_t += np.sum(img2*img3)
    union_t += np.sum(img2)+np.sum(img3)-np.sum(img2*img3)


    intersection = np.sum(img2 * img3)
    union = np.sum(img2) + np.sum(img3) - intersection
    index_iou = [test_img[i],intersection / union]
    test_iou.append(index_iou)
    
    img2_idx_modified = img2[:,:] > 0
    img2[img2_idx_modified] = 255

    img3_idx_modified = img3[:,:] > 0
    img3[img3_idx_modified] = 255
    
    img2 = np.expand_dims(img2,axis=-1)
    img2 = np.concatenate((img2,img2,img2),axis=-1)
    img2 = img2.astype(np.uint8)
    
    img3 = np.expand_dims(img3,axis=-1)
    img3 = np.concatenate((img3,img3,img3),axis=-1)
    img3 = img3.astype(np.uint8)
    
    dst_real = cv2.addWeighted(img1,1,img2,0.5,0)
    dst = cv2.addWeighted(img1,1,img3,0.5,0)
    
#     plt.imshow(dst_real)
#     plt.savefig('testset/real_hightlight/'+test_img[i][0:-4]+'.png')
#     plt.imshow(dst)
#     plt.savefig('testset/pred_hightlight/'+test_img[i][0:-4]+'.png')
#     cv2.imwrite('/content/drive/My Drive/testset/real_highlight_256gs/'+test_img[i][0:-4]+'.png',dst_real)
#     cv2.imwrite('/content/drive/My Drive/testset/pred_highlight_256gs/'+test_img[i][0:-4]+'.png',dst)
    cv2.imwrite('/femoral_nerve_block_computer_vision/testset/real_highlight_256gs/'+test_img[i][0:-4]+'.png',dst_real)
    cv2.imwrite('/femoral_nerve_block_computer_vision/testset/pred_highlight_256gs/'+test_img[i][0:-4]+'.png',dst)
total_iou = intersection_t/union_t
print(total_iou)
print(test_iou)

# Calculate the median IOU of test set
df_testiou = pd.DataFrame(test_iou,columns=['file_name','IoU'])
# df_testiou.sort_values(['IoU'])
print(df_testiou['IoU'].median())
print(df_testiou['IoU'].quantile(0.75))
print(df_testiou['IoU'].quantile(0.25))
# df_testiou.sort_values(['IoU'],ascending=False).to_excel('/content/drive/My Drive/testset/testset_iou_256gs.xlsx',index=False)
df_testiou.sort_values(['IoU'],ascending=False).to_excel('/femoral_nerve_block_computer_vision/drive/My Drive/testset/testset_iou_256gs.xlsx',index=False)

# 准确率 Calculate the precise
np_iou = np.array(test_iou)
right_sum = np.sum((np_iou[:,1].astype(float)>0.5).astype(np.uint8))
print(right_sum/len(test_iou))

# Plot the distribution of IOUs in three groups
plt.figure(num=0,figsize=(8,6))
plt.boxplot(x=[train_ious,val_ious,df_testiou['IoU']],labels=['Trainset(450)','Devset(50)','Testset(62)'],
            medianprops={'color':'black'},boxprops={'linewidth':2},capprops={'linewidth':2},whiskerprops={'linewidth':2})
plt.ylabel('IoU',{'size':20})
plt.xlabel('Different sets',{'size':20})
plt.tick_params(labelsize=15)
# plt.savefig('/content/drive/My Drive/figures/main_fig.tif',dpi=300)
plt.savefig('/femoral_nerve_block_computer_vision/drive/My Drive/figures/main_fig.tif',dpi=300)
plt.show()

# cross validation
from sklearn.model_selection import KFold

num_fold = 0
sum_score = 0
models = []
nfolds = 10
model_name = 'femoral_n_cv'
epochs = 75
batch_size = 32
yfull_train = dict()
scores = []
accus = []

def cv_iou(y_valid, pred_valid):
  pred_valid = (pred_valid > 0.5).astype(np.uint8)
  intersection = np.sum(np.abs(y_valid * pred_valid))
  union = np.sum(y_valid) + np.sum(pred_valid) - intersection
  return (intersection+1) / (union+1)

def cv_accu(y_valid, pred_valid):
  accu_bi = []
  for i in range(len(y_valid)):
    s_iou = cv_iou(y_valid[i], pred_valid[i])
    accu_bi.append((s_iou > 0.5).astype(np.uint(8)))
  return sum(accu_bi)/len(accu_bi)
    

kf = KFold(n_splits=nfolds, shuffle=True, random_state=seed)

total_ids = train_ids + test_ids
X_total = np.concatenate((X_train, X_test), axis=0)
Y_total = np.concatenate((Y_train, Y_test), axis=0)

for train_index, valid_index in kf.split(total_ids):
  model = UNetModel(IMG_HEIGHT,IMG_WIDTH,GS_CHANNELS) 
  cvx_train = X_total[train_index]
  cvy_train = Y_total[train_index]
  cvx_valid = X_total[valid_index]
  cvy_valid = Y_total[valid_index]
  
  num_fold += 1
  print("Start KFold number {} from {}".format(num_fold, nfolds))
  print("Split train: ", len(cvx_train), len(cvy_train))
  print("Split valid: ", len(cvx_valid), len(cvy_valid))
  
  callbacks = [ModelCheckpoint(model_name, verbose=1, save_best_only=True)]
  
  model.fit(cvx_train, cvy_train, batch_size=batch_size, epochs=epochs,
           shuffle=True, verbose=1, validation_data=(cvx_valid, cvy_valid),
           callbacks=callbacks)
  
  pred_valid = model.predict(cvx_valid, batch_size=batch_size, verbose=2)
  score = cv_iou(cvy_valid, pred_valid)
  accu = cv_accu(cvy_valid, pred_valid)
  print("Score iou_coef: ", score)
  print("Accuracy: ", accus)
  scores.append(score)
  accus.append(accu)
  sum_score += score * len(valid_index)
  
  # Store valid predictions
  for i in range(len(valid_index)):
    yfull_train[valid_index[i]] = pred_valid[i] 
  models.append(model)  
# socre = np.median(scores)
# accu = np.median(accus)
print("IoU train independent median: ", np.median(scores), " IQ", np.quantile(scores, 0.25), "-", np.quantile(scores, 0.75))
print("Accuracy independet median: ", np.median(accus), " IQ", np.quantile(accus, 0.25), "-", np.quantile(accus, 0.75))
info_string = "IoU_" + str(score) + "_folds_" + str(nfolds) + "_ep_" + str(epochs)
print (info_string)
  
  
  
  
  
  
  
  
# cvscores = []
# for train, test in kfold.split(X_train, Y_train):
#   model.fit(X_train[train], Y_train[train], epochs=50, batch_size=32, verbose=1)
#   scores = model.evalute(X_train[train], Y_train[test], verbose=0)
#   print("%s: %.2f%%" % (model.metrics_names[1], scores[1]*100))
#   cvscores.append(scores[1]*100)
# print("%.2f%% (+/- %.2f%%)" % (numpy.mean(cvscores), numpy.std(cvscores)))
  
  
# # fit 模型
# def model_fit(X_train,Y_train,model_name,epochs,batch_size,validation_split):
# #     earlystopper = EarlyStopping(patience=5, verbose=1)
#     checkpointer = ModelCheckpoint(model_name, verbose=1, save_best_only=True)
#     results = model.fit(X_train,Y_train,validation_split=validation_split,
#                        batch_size=batch_size,epochs=epochs,
#                        callbacks=[checkpointer])
# model_name = 'femoral_n_256'
# epochs = 50
# batch_size = 32
# validation_split = 0.1
# model_fit(X_train,Y_train,model_name,epochs,batch_size,validation_split)

# Plot the results of cross validation
plt.figure(figsize=(4,3), dpi=300)
x_axis = np.array(range(10)) + 1
plt.plot(x_axis, scores, marker="o", label="Sum IoU")
plt.plot(x_axis, accus, marker="o", label="Accuracy")
plt.xticks(x_axis)
plt.xlabel("Cross validation No.")
plt.yticks(np.linspace(0,1,11))
plt.ylabel("Value")
plt.legend()
# plt.savefig("/content/drive/My Drive/figures/Cross_val.pdf")
plt.savefig("/femoral_nerve_block_computer_vision/drive/My Drive/figures/Cross_val.pdf")
plt.show()